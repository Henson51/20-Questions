{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a6671a",
   "metadata": {},
   "source": [
    "# P2: 20 Questions\n",
    "#### Group 2: Tyler Henson, Tyler Husemann, Brandon Lowery, and Ean Vandergraaf\n",
    "#### 523 Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf795b1",
   "metadata": {},
   "source": [
    "## 0. Background Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f0d3f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For our 20-Questions model, we decided to assign each of the 1850 nouns in the dataset to one of 20 categories. These categories represent broad semantic groups such as Vehicles, Tools, Fruits, Wild Mammals, Buildings & Structures, etc. Our goal was to help the 20-Questions model narrow down possibilities more efficiently during gameplay. Our theory was that we could identify a noun's category within 4-5 questions. Then the model would be able to ask property rating quesitons to precisely pin down the user's noun.\n",
    "\n",
    "The code provided below is our final model. It utilizes 2 external files which were compiled using the `noun_categorizer.py` and `Generate_Ratings.ipynb` files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a1bd0",
   "metadata": {},
   "source": [
    "## 1. 20 Questions AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c472047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load category tree\n",
    "with open('categories_tree.json', 'r') as f:\n",
    "    tree = json.load(f)\n",
    "\n",
    "# Load noun property data\n",
    "with open(\"noun_property_ratings.jsonl\", \"r\") as file:\n",
    "    raw_data = [json.loads(line) for line in file]\n",
    "\n",
    "questions = tree[\"Questions\"]\n",
    "categories = tree[\"Categories\"]\n",
    "\n",
    "# Greedy algorithm to select best question\n",
    "def best_question(noun_data, remaining_nouns, asked_properties, properties, property_types):\n",
    "    best_property = None\n",
    "    best_split_score = float(\"inf\")\n",
    "    best_threshold = None\n",
    "    best_type = None\n",
    "    best_reference = None\n",
    "\n",
    "    for prop in properties:\n",
    "        if prop in asked_properties:\n",
    "            continue\n",
    "\n",
    "        values = [(noun, noun_data[noun][prop]) for noun in remaining_nouns if prop in noun_data[noun]]\n",
    "\n",
    "        if property_types[prop] == \"boolean\":\n",
    "            yes = [v for _, v in values if v == 1]\n",
    "            no = [v for _, v in values if v == 0]\n",
    "            split_score = abs(len(yes) - len(no))\n",
    "\n",
    "            if split_score < best_split_score:\n",
    "                best_property = prop\n",
    "                best_split_score = split_score\n",
    "                best_type = \"binary\"\n",
    "\n",
    "        elif property_types[prop] == \"scale\":\n",
    "            sorted_values = sorted(values, key=lambda x: x[1])\n",
    "            for i in range(1, len(sorted_values)):\n",
    "                threshold = sorted_values[i][1]\n",
    "                yes = [v for _, v in values if v > threshold]\n",
    "                no = [v for _, v in values if v <= threshold]\n",
    "                split_score = abs(len(yes) - len(no))\n",
    "\n",
    "                if 0 < len(yes) < len(values) and split_score < best_split_score:\n",
    "                    best_property = prop\n",
    "                    best_split_score = split_score\n",
    "                    best_threshold = threshold\n",
    "                    best_type = \"continuous\"\n",
    "                    best_reference = sorted_values[i][0]\n",
    "\n",
    "    return best_property, best_type, best_threshold, best_reference\n",
    "\n",
    "def run_ai(questions):\n",
    "    remaining_questions = 20\n",
    "    \n",
    "    # 1. Traverse decision tree to select category\n",
    "\n",
    "    print('Enter 1 for YES, 0 for NO')\n",
    "    node = questions\n",
    "    while not isinstance(node, str):\n",
    "        question = node[\"Question\"]\n",
    "        answer = input(question + \" (0/1): \").strip().lower()\n",
    "        print(f\"{remaining_questions}. {question}: {\"YES\" if answer == \"1\" else \"NO\"}\")\n",
    "        if answer == '1':\n",
    "            node = node[\"YES\"]\n",
    "            remaining_questions -= 1\n",
    "        elif answer == '0':\n",
    "            node = node[\"NO\"]\n",
    "            remaining_questions -= 1\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 1 for YES or 0 for NO.\")\n",
    "            continue\n",
    "\n",
    "    selected_category = node\n",
    "    # print(f\"\\nSelected Category: {selected_category}\")\n",
    "    # print(f\"# of Options: {len(categories[selected_category])}\")\n",
    "\n",
    "    # 2. Use Greedy Algorithm to picm the best questions to ask\n",
    "\n",
    "    # Filter data by selected category\n",
    "    filtered_data = [entry for entry in raw_data if entry[\"category\"] == selected_category]\n",
    "\n",
    "    # Organize data: noun -> {property: rating}\n",
    "    noun_data = {}\n",
    "    property_types = {}\n",
    "    for entry in filtered_data:\n",
    "        noun = entry[\"noun\"]\n",
    "        prop = entry[\"property\"]\n",
    "        rating = entry[\"rating\"]\n",
    "        ptype = entry[\"property_type\"]\n",
    "\n",
    "        if noun not in noun_data:\n",
    "            noun_data[noun] = {}\n",
    "        noun_data[noun][prop] = rating\n",
    "        property_types[prop] = ptype\n",
    "\n",
    "    # Extract all properties\n",
    "    properties = set(property_types.keys())\n",
    "\n",
    "    remaining_nouns = set(noun_data.keys())\n",
    "    asked_properties = set()\n",
    "    question_count = 0\n",
    "\n",
    "    fallback_answer = \"Football\" ## in case there is a problem with our logic, will get the next closest answer\n",
    "    while question_count < 19 and len(remaining_nouns) > 1:\n",
    "        fallback_answer = list(remaining_nouns)[0]\n",
    "        best_prop, prop_type, threshold, reference_noun = best_question(noun_data, remaining_nouns, asked_properties, properties, property_types)\n",
    "\n",
    "        if best_prop is None:\n",
    "            break\n",
    "        \n",
    "        question = \"\"\n",
    "        if prop_type == \"binary\":\n",
    "            question = best_prop\n",
    "            answer = int(input(f\"{question.capitalize()} (0/1): \"))\n",
    "\n",
    "        elif prop_type == \"continuous\":\n",
    "            if reference_noun:\n",
    "                question = \"Is its \" + best_prop + \" greater than the \" + best_prop + \" of a \" + reference_noun + \"?\"\n",
    "                answer = int(input(f\"{question.capitalize()} (0/1):\"))\n",
    "            else:\n",
    "                question = \"Is its \" + best_prop + \" greater than \" + threshold + \"?\"\n",
    "                answer = int(input(f\"{question.capitalize()} (0/1):\"))\n",
    "        print(f\"{remaining_questions}. {question.capitalize()}: {\"YES\" if answer == 1 else \"NO\"}\")\n",
    "        remaining_questions -= 1\n",
    "\n",
    "        # Filter remaining nouns\n",
    "        if prop_type == \"binary\":\n",
    "            remaining_nouns = {noun for noun in remaining_nouns if noun_data[noun].get(best_prop) == (1 if answer == 1 else 0)}\n",
    "        elif prop_type == \"continuous\":\n",
    "            if answer == 1:\n",
    "                remaining_nouns = {noun for noun in remaining_nouns if noun_data[noun].get(best_prop, 0) > threshold}\n",
    "            else:\n",
    "                remaining_nouns = {noun for noun in remaining_nouns if noun_data[noun].get(best_prop, 0) <= threshold}\n",
    "\n",
    "        asked_properties.add(best_prop)\n",
    "        question_count += 1\n",
    "        # print(remaining_nouns)\n",
    "        # print(f\"{len(remaining_nouns)} nouns remaining.\")\n",
    "\n",
    "    guess = list(remaining_nouns)[0] if remaining_nouns else fallback_answer\n",
    "    print(f\"\\nFinal Guess: Are you thinking of '{guess}'?\")\n",
    "    return guess\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde43417",
   "metadata": {},
   "source": [
    "## 2. Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11537906",
   "metadata": {},
   "source": [
    "### Overall Approach and Design Process\n",
    "\n",
    "#### Noun Categorization Method\n",
    "\n",
    "The first part of our 20-Questions model deals with identifying the category of the noun. These categories allow our model to ask smarter questions instead of guessing randomly. These categories represent broad types of things (like Vehicles, Tools, Foods, Animals, etc.). Our group identified 20 distinct categories and formed a binary tree which would lead the model to the correct category (`category_tree.json`).\n",
    "\n",
    "To assign categories, we used the **Phi-3 Mini language model** through **Ollama**. We gave the model:\n",
    "- The list of allowed categories\n",
    "- A brief description of each category\n",
    "- One noun at a time to classify\n",
    "\n",
    "The `noun_categorizer.py` file was used to categorize all our nouns. The Mini model suggested which category each noun belonged to, and we reviewed the results to fix unclear or incorrect assignments. Some nouns were harder to categorize (brand names, fictional characters, slang, etc.), so we refined prompts and re-ran only those. After final adjustments, we combined everything into a single file (`categorized_nouns.json`) containing all nouns and assigned categories. \n",
    "\n",
    "Once the categories were set, the game traversed the tree to guide its questioning strategy. This categorization step was the foundation for the rest of the system, as it directly influenced how efficiently the model could narrow down answers.\n",
    "\n",
    "#### Property Rating Method\n",
    "\n",
    "Once the model has identified a category, it's next move was to start asking rank based questions. These consisted of questions such as \"Is its weight greater than the weight of a trash can?\" This would allow the model to significantly narrow down the list of nouns per category. In order to do this our group prompted the Mini model with all the nouns, categories, and properties. This process can be found in `Generate_Ratings_final.ipynb`.The output, `noun_property_ratings.json`, consisted of all variations of nouns, properties, property types (boolean or scale), and it's noun-property ranking. \n",
    "\n",
    "Once the properties were set, our 20-Questions model used a greedy algorithm to select the next best question. Depending on the answer to that question, our model would decide were to pivot next based on the remaining nouns. The model will continue to ask these ranking based questions until there was 1 option left.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca6118",
   "metadata": {},
   "source": [
    "### Overall Performance\n",
    "\n",
    "After testing the 20 Questions game several times, the results were mixed but generally reasonable. When the noun had a clear and common category, the model tended to guess correctly or very close. For example, words like Tiger, Hamburger, and Ice Cream were guessed correctly. Words with slightly broader or overlapping meanings were sometimes guessed as something similar instead of exact. For example, during testing, trying to guess Bulldog resulted in the model suggesting Poodle. This shows that the model understands the general type of animal, but its narrowing logic isn't always precise.\n",
    "\n",
    "Some nouns still challenge the model, especially:\n",
    "- Fictional characters\n",
    "- Objects with multiple meanings\n",
    "- Nouns that fit more than one possible category\n",
    "\n",
    "So the model usually narrowed the search down to a similar group rather than something completely unrelated, which indicates that the category system is working as intended. With more tuning in how questions are selected and how properties are weighted, the model’s accuracy could likely improve further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b70927",
   "metadata": {},
   "source": [
    "### Example Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f1052be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: YES\n",
      "18. Is it an animal?: YES\n",
      "17. Is it a mammal?: YES\n",
      "16. Is it a domesticated pet or farm animal?: NO\n",
      "15. Is its speed greater than the speed of a hedgehog?: YES\n",
      "14. Is it a predator?: YES\n",
      "13. Is its size greater than the size of a leopard?: YES\n",
      "12. Is it african?: NO\n",
      "11. Is it social?: NO\n",
      "10. Does it hibernate?: NO\n",
      "9. Is it endangered?: YES\n",
      "8. Is it nocturnal?: NO\n",
      "7. Is it herbivore?: NO\n",
      "\n",
      "Final Guess: Are you thinking of 'tiger'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tiger'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## tiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "953ce40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: NO\n",
      "19. Is it a vehicle or mode of transportation?: YES\n",
      "18. Does it have an engine or motor?: YES\n",
      "17. Does it fly?: YES\n",
      "16. Is its cost greater than the cost of a thruster?: YES\n",
      "15. Does it have wings?: YES\n",
      "14. Is its size greater than the size of a airplane?: YES\n",
      "13. Does it need a runway?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'jet'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jet'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## airplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e5c504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: NO\n",
      "18. Is it a prepared dish or meal (cooked/assembled)?: YES\n",
      "17. Is its healthy greater than the healthy of a mojito?: NO\n",
      "16. Is its complexity greater than the complexity of a cake?: NO\n",
      "15. Is it dessert?: NO\n",
      "14. Is it cuisine-specific?: NO\n",
      "13. Does it have meat?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'hamburger'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hamburger'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## hamburger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afb061a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: YES\n",
      "18. Is it an animal?: NO\n",
      "17. Is it a tree?: NO\n",
      "16. Is it colorful: YES\n",
      "15. Is its height greater than the height of a lilac?: NO\n",
      "14. Is it annual?: NO\n",
      "13. Is it fragrant?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'lilac'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lilac'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## dandelion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee8efd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: NO\n",
      "Invalid input. Please enter 1 for YES or 0 for NO.\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: NO\n",
      "18. Is it a prepared dish or meal (cooked/assembled)?: YES\n",
      "17. Is its healthy greater than the healthy of a mojito?: NO\n",
      "16. Is its complexity greater than the complexity of a cake?: NO\n",
      "15. Is it dessert?: YES\n",
      "14. Does it have dairy?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'ice cream'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ice cream'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## ice cream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ffc63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: YES\n",
      "18. Is it an animal?: YES\n",
      "17. Is it a mammal?: YES\n",
      "16. Is it a domesticated pet or farm animal?: NO\n",
      "15. Is its speed greater than the speed of a hedgehog?: YES\n",
      "14. Is it a predator?: NO\n",
      "13. Is it herbivore?: NO\n",
      "12. Is it social?: YES\n",
      "11. Is it african?: NO\n",
      "10. Does it hibernate?: NO\n",
      "9. Is it endangered?: NO\n",
      "8. Is it nocturnal?: NO\n",
      "\n",
      "Final Guess: Are you thinking of 'ferret'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ferret'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## shaquille o'neal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b13db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: NO\n",
      "19. Is it a vehicle or mode of transportation?: NO\n",
      "18. Is it a natural formation or geological feature?: NO\n",
      "17. Is it primarily infrastructure for transportation (roads, bridges, airports, etc.)?: NO\n",
      "16. Is it a building or large structure?: YES\n",
      "15. Is its size greater than the size of a yard?: YES\n",
      "14. Is it residential?: NO\n",
      "13. Is it a landmark?: YES\n",
      "12. Is it urban?: YES\n",
      "11. Is it tall?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'eiffel tower'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eiffel tower'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## eiffel tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6aa1b305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: NO\n",
      "19. Is it a vehicle or mode of transportation?: NO\n",
      "18. Is it a natural formation or geological feature?: NO\n",
      "17. Is it primarily infrastructure for transportation (roads, bridges, airports, etc.)?: NO\n",
      "16. Is it a building or large structure?: NO\n",
      "15. Is it a physical object you can hold in your hands?: YES\n",
      "14. Is its sharpness greater than the sharpness of a ladder?: NO\n",
      "13. Is its weight greater than the weight of a trash can?: NO\n",
      "12. Is it a tool?: NO\n",
      "11. Is it a household item?: YES\n",
      "10. Is it electricity powered?: YES\n",
      "9. Is it metal?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'desk lamp'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'desk lamp'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc9c850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: YES\n",
      "18. Is it an animal?: YES\n",
      "17. Is it a mammal?: YES\n",
      "16. Is it a domesticated pet or farm animal?: YES\n",
      "15. Is its social greater than the social of a buffalo?: YES\n",
      "14. Is its maintenance greater than the maintenance of a cavalier king charles spaniel?: NO\n",
      "13. Is its trainable greater than the trainable of a cavalier king charles spaniel?: YES\n",
      "12. Is it an indoor pet?: YES\n",
      "11. Is its lifespan greater than the lifespan of a miniature schnauzer?: YES\n",
      "10. Does it have fur?: YES\n",
      "9. Is it for work?: NO\n",
      "8. Is it a pet?: YES\n",
      "7. Is it a carnivore?: YES\n",
      "\n",
      "Final Guess: Are you thinking of 'poodle'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'poodle'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## bulldog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e3a6c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for YES, 0 for NO\n",
      "20. Is it a living thing or was it ever alive?: YES\n",
      "19. Is it currently alive (not a food or processed product)?: YES\n",
      "18. Is it an animal?: YES\n",
      "17. Is it a mammal?: YES\n",
      "16. Is it a domesticated pet or farm animal?: NO\n",
      "15. Is its speed greater than the speed of a hedgehog?: YES\n",
      "14. Is it a predator?: NO\n",
      "13. Is it herbivore?: NO\n",
      "12. Is it social?: YES\n",
      "11. Is it african?: NO\n",
      "10. Does it hibernate?: NO\n",
      "9. Is it endangered?: NO\n",
      "8. Is it nocturnal?: NO\n",
      "\n",
      "Final Guess: Are you thinking of 'ferret'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ferret'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ai(tree[\"Questions\"]) ## superman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234253e",
   "metadata": {},
   "source": [
    "### Performance Summary\n",
    "\n",
    "After running our 20 Questions bot 10 times we had some varying responses.\n",
    "\n",
    "<table>\n",
    "    <th>Noun</th>\n",
    "    <th>Guess</th>\n",
    "    <th># of Questions</th>\n",
    "    <th>Correctness</th>\n",
    "    <tr>\n",
    "        <td>Tiger</td>\n",
    "        <td>Tiger</td>\n",
    "        <td>14</td>\n",
    "        <td><span style=\"color: green; font-weight: bold;\">Correct</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Airplane</td>\n",
    "        <td>Jet</td>\n",
    "        <td>8</td>\n",
    "        <td><span style=\"color: yellow;\">Nearly Close</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Hamburger</td>\n",
    "        <td>Hamburger</td>\n",
    "        <td>8</td>\n",
    "        <td><span style=\"color: green; font-weight: bold;\">Correct</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Dandelion</td>\n",
    "        <td>Lilac</td>\n",
    "        <td>8</td>\n",
    "        <td><span style=\"color: yellow;\">Nearly Close</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ice Cream</td>\n",
    "        <td>Ice Cream</td>\n",
    "        <td>9</td>\n",
    "        <td><span style=\"color: green; font-weight: bold;\">Correct</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Shaquille O'neal</td>\n",
    "        <td>Ferret</td>\n",
    "        <td>13</td>\n",
    "        <td><span style=\"color: red; font-weight: bold;\">Wrong</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Eiffel Tower</td>\n",
    "        <td>Eiffel Tower</td>\n",
    "        <td>10</td>\n",
    "        <td><span style=\"color: green; font-weight: bold;\">Correct</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Guitar</td>\n",
    "        <td>Desk Lamp</td>\n",
    "        <td>12</td>\n",
    "        <td><span style=\"color: red; font-weight: bold;\">Wrong</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bulldog</td>\n",
    "        <td>Poodle</td>\n",
    "        <td>14</td>\n",
    "        <td><span style=\"color: yellow;\">Nearly Close</span></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Superman</td>\n",
    "        <td>Ferret</td>\n",
    "        <td>13</td>\n",
    "        <td><span style=\"color: red; font-weight: bold;\">Wrong</span></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8feff",
   "metadata": {},
   "source": [
    "### Future Work and Limitations\n",
    "\n",
    "A portion of nouns were difficult to classify:\n",
    "- Brand names  \n",
    "- Fictional characters  \n",
    "- Very technical or niche terms  \n",
    "- Ambiguous or slang words  \n",
    "\n",
    "Some of these were initially placed in “Other” or left uncategorized. We re-ran those nouns separately with refined prompting to reduce the number of unclear results. A small number may still remain ambiguous.\n",
    "\n",
    "Overall, the game worked well once we had a full categorized noun list. It was able to narrow things down quickly in most runs. The times it struggled were usually with nouns that are a bit unclear, like fictional characters, celebrities, or things that don’t fit cleanly into one category. In those cases, the model sometimes chose something “close” but not correct.\n",
    "\n",
    "If we continued this project, we would focus on:\n",
    "- Breaking some categories into smaller or more specific groups (especially for people/characters).\n",
    "- Giving the model short definitions or context for tricky nouns to help it understand them better.\n",
    "- Letting the game learn from previous wrong guesses to improve over time.\n",
    "- Fine tuning the initial question asked. \n",
    "\n",
    "These improvements would help reduce the number of “almost” or incorrect guesses and make the game more consistent overall.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
